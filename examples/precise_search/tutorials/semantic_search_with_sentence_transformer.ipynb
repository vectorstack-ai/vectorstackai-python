{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial demonstrates how to use PreciseSearch to build a semantic search application that retrieves the most relevant passages for a given query.\n",
    "\n",
    "### Implementation Steps\n",
    "1. Setup Knowledge Base â€“ We will use the [MS MARCO dataset](https://huggingface.co/datasets/microsoft/ms_marco), which contains real Bing search queries paired with relevant passages to construct a knowledge base.\n",
    "2. Embedding Generation â€“ Generate vector embeddings for queries and passages using [Sentence Transformers library](https://sbert.net/).\n",
    "3. Indexing for Search â€“ Build an efficient search index with PreciseSearch's SDK for fast and accurate retrieval.\n",
    "\n",
    "By the end, you'll have a fully functional semantic search system capable of understanding natural language queries. ðŸš€ \n",
    "\n",
    "Note, the sentence-transformers library is an excellent choice for experimenting with different embedding models and enabling private deployments. However, if you lack GPU access, consider using an integrated embedding model from [VectorStackAI](https://vectorstack.ai) or a cloud-based API such as [OpenAIâ€™s](https://platform.openai.com/docs/guides/embeddings) or [Googleâ€™s](https://ai.google.dev/gemini-api/docs/embeddings) for efficient inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install dependencies\n",
    "\n",
    "To get started, install the required Python packages:\n",
    "\n",
    "- `sentence-transformers`: Sentence Transformers Python SDK for generating embeddings for queries and passages.\n",
    "- `vectorstackai`: A package for building and querying semantic search indexes. It provides seamless integration with PreciseSearch, a high-performance search solution from [VectorStackAI](https://vectorstack.ai), designed for efficient and accurate retrieval.\n",
    "- `datasets, huggingface_hub, fsspec`: Libraries to load and process the MS MARCO dataset.\n",
    "\n",
    "\n",
    "Run the following command to install the packages (note this may take some time):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install sentence-transformers, vectorstackai \n",
    "%pip install sentence-transformers vectorstackai\n",
    "# Install datasets, huggingface_hub and fsspec for loading the MS MARCO dataset\n",
    "%pip install -q datasets huggingface_hub fsspec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and prepare the dataset (MS MARCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/venv/temp_sentence_transformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Download and prepare the dataset (MS MARCO) from Hugging Face\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  was ronald reagan a democrat\n",
      "List of passages: \n",
      "In his younger years, Ronald Reagan was a member of the Democratic Party and campaigned for Democratic candidates; however, his views grew more conservative over time, and in the early 1960s he officially became a Republican. In November 1984, Ronald Reagan was reelected in a landslide, defeating Walter Mondale and his running mate Geraldine Ferraro (1935-), the first female vice-presidential candidate from a major U.S. political party.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "From Wikipedia, the free encyclopedia. A Reagan Democrat is a traditionally Democratic voter in the United States, especially a white working-class Northerner, who defected from their party to support Republican President Ronald Reagan in either or both the 1980 and 1984 elections. During the 1980 election a dramatic number of voters in the U.S., disillusioned with the economic 'malaise' of the 1970s and the presidency of Jimmy Carter (even more than, four years earlier, Liberal Republican Gerald Ford), supported former California governor (and former Democrat) Ronald Reagan.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ronald Reagan began his political life in the Democratic Party, but as he became more and more conservative, he ultimately changed to the Republican Party in the early 1960s. Yes, he switched parties in 1962. He said that he did not desert the Democrats but rather they deserted him. Yes, Ronald Reagan was a member of the Democratic Party until he s â€¦ witched to the Republican Party in 1962, at the age of 51. 8 people found this useful.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ronald Wilson Reagan (/ËˆrÉ’nÉ™ld ËˆwÉªlsÉ™n ËˆreÉªÉ¡É™n/ ; February 6, 1911 â€“ June 5, 2004) was an American politician, commentator, and actor, who served as the 40th President of the United States from 1981 to 1989. I think Ronald Reagan changed the trajectory of America in a way that Richard Nixon did not and in a way that Bill Clinton did not. He put us on a fundamentally different path because the country was ready for it.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "When Reagan was a 'liberal Democrat'. In 1948, a very different sounding Ronald Reagan campaigned on the radio for Democrat Harry Truman. Listen to the old audio recording. ... more Duration: {{video.duration.momentjs}}. \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ronald Reagan (1911-2004), a former actor and California governor, served as the 40th U.S. president from 1981 to 1989. Raised in small-town Illinois, he became a Hollywood actor in his 20s and later served as the Republican governor of California from 1967 to 1975. In November 1984, Ronald Reagan was reelected in a landslide, defeating Walter Mondale and his running mate Geraldine Ferraro (1935-), the first female vice-presidential candidate from a major U.S. political party.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1984 Re-Election. In November 1984, Ronald Reagan was re-elected in a landslide, defeating Democratic challenger Walter Mondale. Reagan carried 49 of the 50 U.S. states in the election, and received 525 of 538 electoral votesâ€”the largest number ever won by an American presidential candidate. \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# We will use the first 100 samples from the training set\n",
    "ds_tutorial = ds['train'].select(range(100))\n",
    "\n",
    "sample = ds_tutorial[1]\n",
    "\n",
    "# Each sample contains:\n",
    "# query: the question\n",
    "# list_of_passages: a list of passages which are relevant to the question\n",
    "query = sample['query']\n",
    "list_of_passages = sample['passages']['passage_text']\n",
    "\n",
    "print('Query: ', query)\n",
    "print('List of passages: ')\n",
    "for passage in list_of_passages:\n",
    "    print(passage)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected  814  passages for our knowledge base\n"
     ]
    }
   ],
   "source": [
    "# We will collect all the passage texts to make our knowledge base\n",
    "knowledge_base = []\n",
    "for sample in ds_tutorial:\n",
    "    list_of_passages = sample['passages']['passage_text']\n",
    "    knowledge_base.append(list_of_passages)\n",
    "\n",
    "# Flatten the list of passages\n",
    "knowledge_base = [item for sublist in knowledge_base for item in sublist]\n",
    "\n",
    "print('Collected ', len(knowledge_base), ' passages for our knowledge base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate embeddings for the knowledge base\n",
    "\n",
    "Now that we have our knowledge base, we need to generate embeddings for each passage.\n",
    "\n",
    "We will use OpenAI's API to generate embeddings for each passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for the knowledge base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:00<00:00, 43.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation is done!\n",
      "Generated embeddings for 814 passages\n",
      "Dimensions of the embeddings: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Instantiate the MiniLM-L6 model from sentence-transformers \n",
    "model = SentenceTransformer('sentence-transformers/msmarco-MiniLM-L6-cos-v5')\n",
    "\n",
    "# Generate embeddings for the knowledge base\n",
    "print('Generating embeddings for the knowledge base...')\n",
    "all_embeddings = model.encode(knowledge_base, show_progress_bar=True)\n",
    "\n",
    "# Convert from numpy array to List[List[float]]\n",
    "all_embeddings = all_embeddings.tolist()\n",
    "\n",
    "\n",
    "print('Embedding generation is done!')\n",
    "# Embeddings are stored in the `all_embeddings` numpy array\n",
    "print(f'Generated embeddings for {len(all_embeddings)} passages') \n",
    "print(f'Dimensions of the embeddings: {len(all_embeddings[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a search index\n",
    "\n",
    "With our knowledge base ready, it's time to build a search index for efficient retrieval.\n",
    "We'll use **PreciseSearch** to create a high-performance index, enabling fast and accurate passage retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request accepted: Index creation for 'ms_marco_dense_index' started.\n",
      "Index is not ready yet. Waiting for 2 seconds...\n",
      "Connected to the index\n"
     ]
    }
   ],
   "source": [
    "from vectorstackai import PreciseSearch\n",
    "import time\n",
    "\n",
    "precise_search_client = PreciseSearch(\n",
    "    api_key=\"your_api_key\"\n",
    "    ) # Replace with your own PreciseSearch API key\n",
    "\n",
    "# Create the index \n",
    "precise_search_client.create_index(index_name=\"ms_marco_dense_index\", \n",
    "                                   dimension=len(all_embeddings[0]), # The dimension of the embeddings\n",
    "                                   metric=\"cosine\", # The metric to use for the search\n",
    "                                   features_type=\"dense\") # The type of features to use for the search\n",
    "\n",
    "# Wait for the index to be ready\n",
    "while precise_search_client.index_status(index_name=\"ms_marco_dense_index\") != \"ready\":\n",
    "    time.sleep(2)\n",
    "    print(\"Index is not ready yet. Waiting for 2 seconds...\")\n",
    "    \n",
    "# Connect to the index\n",
    "index = precise_search_client.connect_to_index(index_name=\"ms_marco_dense_index\")\n",
    "print('Connected to the index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Upload dense embeddings to the index\n",
    "\n",
    "Upserting into a dense index requires a batch of IDs and dense vectors. Optionally, you can provide metadata for each passage.\n",
    "\n",
    "- Required inputs:\n",
    "   - batch_ids (List[str]): Unique identifiers for each passage.\n",
    "   - batch_vectors (List[List[float]]): Embeddings for each passage.\n",
    "- Optional inputs:\n",
    "   - batch_metadata (List[Dict[str, Any]]): Metadata for each passage, can store any additional information about the items in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings uploaded to the index\n"
     ]
    }
   ],
   "source": [
    "# Convert the data in the required format\n",
    "batch_ids = [str(i) for i in list(range(len(knowledge_base)))]\n",
    "batch_vectors = all_embeddings\n",
    "batch_metadata = [{\"text\": passage} for passage in knowledge_base]\n",
    "\n",
    "index.upsert(batch_ids=batch_ids, \n",
    "             batch_vectors=batch_vectors, \n",
    "             batch_metadata=batch_metadata)\n",
    "print('Embeddings uploaded to the index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Querying the index\n",
    "\n",
    "Now that we have uploaded the data to the index, we can query it. \n",
    "\n",
    "Given an input query as a text, we will first compute the embedding for the query and then search for the most relevant passages in the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n",
      "0.65966796875\n",
      "{'text': 'Cooked Food: Leftover, cooked foods should be kept in the refrigerator in an airtight container and eaten within 4-5 days. Food, whether cooked or not, should not be left at room temperature for more than 4 hours otherwise the risk of food poisoning increases. You can refrigerate them for up to 5 days as long as they are stored properly â€” wrapped in a paper towel and then sealed inside a plastic bag. Fresh Beans/Peas: Depending on the variety, they can be kept, tightly wrapped, in the refrigerator for 3-5 days.'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "663\n",
      "0.60888671875\n",
      "{'text': 'Kitchen Fact: Cooked food stored in the refrigerator should be eaten in 3 to 4 days. After food is cooked, it should sit out at room temperature no more than two hours before being refrigerated to slow down bacteria growth. But once stored in the fridge, leftovers should be eaten up within three to four days because bacteria can still grow even at refrigerator temperatures. To help you remember how long something has been in the fridge, we recommend labeling it with the date it was cooked to help you keep track!'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "666\n",
      "0.56689453125\n",
      "{'text': \"Uncooked foods, such as cold salads or sandwiches, also should be eaten or refrigerated promptly. Your goal is to minimize the time a food is in the danger zone â€” between 40 and 140 F (4 and 60 C) â€” when bacteria can quickly multiply. When you're ready to eat leftovers, reheat them on the stove, in the oven or in the microwave until the internal temperature reaches 165 F (74 C). After that, the risk of food poisoning increases. If you don't think you'll be able to eat leftovers within four days, freeze them immediately. Food poisoning â€” also called foodborne illness â€” is caused by harmful organisms, such as bacteria in contaminated food.\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "662\n",
      "0.50830078125\n",
      "{'text': 'Cooked food sitting at room temperature is in what the USDA calls the Danger Zone, which is between 40 Â° F and 140 Â° F. In this range of temperatures, bacteria grows rapidly and the food can become unsafe to eat, so it should only be left out no more than two hours. '}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "660\n",
      "0.4833984375\n",
      "{'text': 'Yes. Leftovers should be used within 2 days and stored in the fridge at between 0-5Â°C during this time. They can be reheated as long as they are heated to 70Â°C or higher. Food should be very hot and steaming before it is served. '}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"How should I store cooked food\"\n",
    "\n",
    "# Compute the embedding for the query\n",
    "query_embedding = model.encode(query).tolist()\n",
    "\n",
    "# Search for the most relevant passages\n",
    "search_results = index.search(query_vector=query_embedding, \n",
    "                       top_k=5\n",
    "                       )\n",
    "\n",
    "# Print the results\n",
    "for result in search_results:\n",
    "    print(result['id'])\n",
    "    print(result['similarity'])\n",
    "    print(result['metadata'])\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search results are returned as a list of dictionaries, where each dictionary contains the following keys:\n",
    "\n",
    "- `id`: The identifier of the matching document/vector.\n",
    "- `similarity`: The similarity score for the match (higher is typically more relevant).\n",
    "- `metadata`: Any additional metadata stored with the vector (only returned if `return_metadata=True`).\n",
    "\n",
    "In the search results shown above, we can note the following:\n",
    "\n",
    "- The results are sorted by similarity score, meaning the first result is the most relevant.\n",
    "- The results are relevant to the query!\n",
    "\n",
    "## 7. Clean up\n",
    "Feel free to play with the query and see the results. You can also experiment with other models available via [SentenceTransformer library](https://sbert.net/docs/sentence_transformer/pretrained_models.html#).\n",
    "\n",
    "\n",
    "Once you are done with the tutorial, you can delete the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure you want to delete index 'ms_marco_dense_index'? This action is irreversible.\n",
      "Index deletion for 'ms_marco_dense_index' started.\n"
     ]
    }
   ],
   "source": [
    "precise_search_client.delete_index(index_name=\"ms_marco_dense_index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (temp_sentence_transformer)",
   "language": "python",
   "name": "temp_sentence_transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
